{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training ResNet34 for ship detection (ship/no-ship)\n",
    "## Overview\n",
    "We've downloaded a pretrained ResNet34 model and retrained it on our dataset for ship detection task. Later we'll use this model as a backbone in our U-Net architecture model for ships segmentation. \n",
    "After training of the head layers of the model on 256x256 rescaled images for one epoch the accuracy has reached ~94%. The following fine-tuning of entire model for 2 more epochs with learning rate annealing boosted the accuracy to ~97%. We then continued training for several epochs with a new data set composed of images of 384x384 resolution, the accuracy had boosted to ~98%. Unfortunately, continuing training the model on full resolution, 768x768, images leaded to reduction of the accuracy that is likely attributed to insufficient model capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from old.fastai.conv_learner import *\n",
    "from old.fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PATH = 'C:/Users/User/Desktop/Avshalom&Naama/jupyter_files/fastai-master/'\n",
    "TRAIN = '../../data/train_v2/'\n",
    "TEST = '../../data/test_v2/'\n",
    "SEGMENTATION = '../../data/train_ship_segmentations_v2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Split train-validation\n",
    "Split train data to train set and validation set. 5% of the train data is sufficient for model evaluation thus split ratio is set to 5% validation / 95% train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data utils\n",
    "### Data loader\n",
    "Implements get_image(), get_grountruth() and get_num_classes().\n",
    "### Get Data\n",
    "Generate input data for training stage. also perform augmentations and transformations on original data for better generalization performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architectur\n",
    "arch = resnet34\n",
    "\n",
    "# Data loader (for data handeling)\n",
    "class pdFilesDataset(FilesDataset):\n",
    "    \n",
    "    # Constructor/Initializator - create a dictionary of the train images and their segmentation data.\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    # Get image i\n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    # Get segmentation for image i\n",
    "    # if in test/validation - return 0\n",
    "    def get_y(self, i):\n",
    "        if(self.path == TEST): return 0\n",
    "        masks = self.segmentation_df.loc[self.fnames[i]]['EncodedPixels']\n",
    "        if(type(masks) == float): return 0 #NAN - no ship \n",
    "        else: return 1\n",
    "    \n",
    "    # Get number of classes in dataset\n",
    "    # classes = (ship, no-ship)\n",
    "    def get_c(self): return 2 #number of classes\n",
    "\n",
    "# Generate augmented and transformed dataset for NN Train use.\n",
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(20, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=4, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model\n",
    "### Model parameters\n",
    "set image size, batch size, number of epochs, optimizer type, initial learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "sz = 256                # image size\n",
    "bs = 64                 # batch size\n",
    "num_eps = 1             # number of epochs\n",
    "optimizer = optim.Adam  # optimizer type\n",
    "lr = 2e-3               # initial learning rate\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "learn.opt_fn = optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "we first started to train on low resolution images (256x256) for few epochs and only then we trained on higher resolution images (384x384).  we used this method for few reasons: shorter train time, GPU memory constrains and most important â€“ improving the model generalizing abilities by training with low-res images.\n",
    "\n",
    "### Train on low resolution images\n",
    "Train the head of the model with lr=2e-3 for 1 epoch. Then, unfreeze the rest of the model and train the head, middle and base of the model with lr =  2e-3, 5e-4 and 2e-3 respectevly for 2 more epochs since low level detector do not vary much from one image data set to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "learn.metrics=[accuracy,\n",
    "               Precision(),\n",
    "               Recall()]\n",
    "learn.fit(lr, num_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr=np.array([1e-4,5e-4,2e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=2, use_clr=(20,8))\n",
    "learn.save('Resnet34_lable_256_1')\n",
    "#learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on high resolution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Training on high resolution images\n",
    "sz = 384 #image size\n",
    "bs = 32  #batch size\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.unfreeze()\n",
    "lr=np.array([1e-4,5e-4,2e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "learn.load('Resnet34_lable_256_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr/2, 1, cycle_len=2, use_clr=(20,8)) #lr is smaller since bs is only 32\n",
    "learn.save('Resnet34_lable_384_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc presicion & recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Resnet34_lable_384_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict \n",
    "Every prediction above probability of 0.5 is counted as ship, else - no-ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "log_preds_384,y_384 = learn.predict_with_targs(is_test=True)\n",
    "probs_384 = np.exp(log_preds_384)[:,1]\n",
    "pred_384 = (probs_384 > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_384 = pd.DataFrame({'id':test_names, 'p_ship':probs_384})\n",
    "df_384.to_csv('ship_detection_384.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Visuailzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#ship_detection = pd.read_csv('ship_detection_256.csv')    # for 256x256 classifier\n",
    "ship_detection = pd.read_csv('ship_detection_384.csv')    # for 384x384 classifier\n",
    "test_names = ship_detection.loc[ship_detection['p_ship'] > 0.5, ['id']]['id'].values.tolist()\n",
    "test_names_nothing = ship_detection.loc[ship_detection['p_ship'] <= 0.5, ['id']]['id'].values.tolist()\n",
    "len(test_names), len(test_names_nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "n = 16\n",
    "rands = np.random.choice(len(test_names), n)\n",
    "columns = 4\n",
    "rows = n//4 + 1\n",
    "fig=plt.figure(figsize=(columns*4, rows*4))\n",
    "fig.suptitle('Classified as SHIP', fontsize=16)\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        idx = j+i*columns\n",
    "        if idx >= n: break\n",
    "        fig.add_subplot(rows, columns, idx+1)\n",
    "        plt.axis('off')\n",
    "        img = np.array(Image.open(os.path.join(TEST,test_names[rands[idx]])))\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rands = np.random.choice(len(test_names_nothing), n)\n",
    "fig=plt.figure(figsize=(columns*4, rows*4))\n",
    "fig.suptitle('Classified as NO-SHIP', fontsize=16)\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        idx = j+i*columns\n",
    "        if idx >= n: break\n",
    "        fig.add_subplot(rows, columns, idx+1)\n",
    "        plt.axis('off')\n",
    "        img = np.array(Image.open(os.path.join(TEST,test_names_nothing[rands[idx]])))\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
